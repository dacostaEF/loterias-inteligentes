#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AN√ÅLISE ESTAT√çSTICA AVAN√áADA - LOTOF√ÅCIL
====================================

M√≥dulo contendo an√°lises estat√≠sticas avan√ßadas para a Quina:
1. üìä Desvio padr√£o: variabilidade na distribui√ß√£o
2. üé≤ Teste de aleatoriedade: verificar se os sorteios s√£o realmente aleat√≥rios
3. üîó An√°lise de clusters: agrupamentos de n√∫meros
4. üìà Correla√ß√£o entre n√∫meros: quais tendem a sair juntos
5. üéØ Probabilidades condicionais: chance de um n√∫mero sair dado que outro saiu

Autor: Sistema IA Quina
Data: 2024
Vers√£o: An√°lises Estat√≠sticas Avan√ßadas
"""

import numpy as np
import pandas as pd
from scipy import stats
from scipy.stats import chi2_contingency, pearsonr, spearmanr
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def limpar_nan_do_dict(d):
    """Remove valores NaN de dicion√°rios aninhados"""
    if isinstance(d, dict):
        return {k: limpar_nan_do_dict(v) for k, v in d.items()}
    elif isinstance(d, list):
        return [limpar_nan_do_dict(v) for v in d]
    elif isinstance(d, (int, float)):
        if np.isnan(d):
            return 0.0
        return d
    else:
        return d

class AnaliseEstatisticaAvancadaLotofacil:
    """
    Classe para an√°lises estat√≠sticas avan√ßadas da Quina
    """
    
    def __init__(self, df_lotofacil):
        """
        Inicializa a an√°lise com os dados da Quina
        
        Args:
            df_quina (pd.DataFrame): DataFrame com os dados dos sorteios
        """
        self.df = df_lotofacil
        self.colunas_bolas = [f'Bola{i}' for i in range(1, 16)]
        # Preparar dados para an√°lise
        self._preparar_dados()
        
        if self.df_validos is None or len(self.df_validos) == 0:
            logger.error("‚ùå Nenhum dado v√°lido encontrado para an√°lise")
            return None
            
        # logger.info(f"Dados preparados: {len(self.df_validos)} concursos v√°lidos")
    
    def _preparar_dados(self):
        """Prepara e valida os dados para an√°lise"""
        if self.df is None or self.df.empty:
            logger.error("DataFrame vazio ou None")
            return
        
        # Limpar e validar dados (Lotof√°cil)
        self.df_limpo = self.df.dropna(subset=self.colunas_bolas).copy()
        
        # Converter para num√©rico
        for col in self.colunas_bolas:
            self.df_limpo[col] = pd.to_numeric(self.df_limpo[col], errors='coerce').astype('Int64')
        
        # Filtrar dados v√°lidos (Lotof√°cil: 1-25)
        mask_bolas = self.df_limpo[self.colunas_bolas].notna().all(axis=1) & \
                    (self.df_limpo[self.colunas_bolas] >= 1).all(axis=1) & \
                    (self.df_limpo[self.colunas_bolas] <= 25).all(axis=1)
        
        self.df_validos = self.df_limpo[mask_bolas]
        
        if self.df_validos.empty:
            logger.error("Nenhum dado v√°lido encontrado ap√≥s limpeza")
            return
        
        logger.info(f"Dados preparados: {len(self.df_validos)} concursos v√°lidos")
    
    def calcular_desvio_padrao_distribuicao(self):
        """
        Calcula o desvio padr√£o da distribui√ß√£o dos n√∫meros
        
        Returns:
            dict: Estat√≠sticas de desvio padr√£o
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Calcular frequ√™ncia de cada n√∫mero (1-25 para Lotof√°cil)
        frequencias = {}
        for num in range(1, 26):
            count = 0
            for _, row in self.df_validos.iterrows():
                if num in row[self.colunas_bolas].values:
                    count += 1
            frequencias[num] = count
        
        # Calcular estat√≠sticas
        valores = list(frequencias.values())
        media = float(np.mean(valores))
        desvio_padrao = float(np.std(valores))
        variancia = float(np.var(valores))
        coeficiente_variacao = (desvio_padrao / media) * 100 if media > 0 else 0
        
        # Ordenar n√∫meros por variabilidade
        numeros_variaveis = sorted(frequencias.items(), key=lambda x: x[1], reverse=True)
        
        return {
            'estatisticas_gerais': {
                'media_frequencia': media,
                'desvio_padrao': desvio_padrao,
                'variancia': variancia,
                'coeficiente_variacao': coeficiente_variacao
            },
            'numeros_mais_variaveis': numeros_variaveis,
            'frequencias_completas': frequencias
        }
    
    def teste_aleatoriedade(self):
        """
        Testa se os sorteios s√£o realmente aleat√≥rios
        
        Returns:
            dict: Resultados dos testes de aleatoriedade
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Teste Chi-quadrado para uniformidade
        frequencias = []
        for num in range(1, 26):
            count = 0
            for _, row in self.df_validos.iterrows():
                if num in row[self.colunas_bolas].values:
                    count += 1
            frequencias.append(count)
        
        # Valor esperado para cada n√∫mero (uniforme)
        total_sorteios = len(self.df_validos)
        esperado = (total_sorteios * 15) / 25  # 15 n√∫meros por sorteio, 25 n√∫meros poss√≠veis
        
        # Teste Chi-quadrado
        chi2_stat, p_value = stats.chisquare(frequencias, [esperado] * 25)
        
        # Interpreta√ß√£o
        if p_value < 0.05:
            interpretacao = "N√£o aleat√≥rio (p < 0.05)"
        else:
            interpretacao = "Aleat√≥rio (p >= 0.05)"
        
        # Teste de paridade (pares vs √≠mpares)
        pares_por_sorteio = []
        for _, row in self.df_validos.iterrows():
            numeros = row[self.colunas_bolas].values
            pares = sum(1 for num in numeros if num % 2 == 0)
            pares_por_sorteio.append(pares)
        
        media_pares = float(np.mean(pares_por_sorteio))
        # Em 15 n√∫meros, esperamos em m√©dia 7.5 pares
        aleatorio_paridade = abs(media_pares - 7.5) < 1.0
        
        return {
            'teste_chi_quadrado': {
                'chi2': chi2_stat,
                'p_value': p_value,
                'interpretacao': interpretacao
            },
                'teste_paridade': {
                'media_pares': media_pares,
                'aleatorio_paridade': aleatorio_paridade
            }
        }
    
    def analise_clusters(self, n_clusters=5):
        """
        An√°lise de clusters para agrupar n√∫meros similares (SIMPLIFICADA)
        
        Args:
            n_clusters (int): N√∫mero de clusters desejados
            
        Returns:
            dict: Resultados da an√°lise de clusters
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Para poucos concursos, retornar clusters b√°sicos
        if len(self.df_validos) < 20:
            return {
                'clusters': {'cluster_0': [1, 2, 3, 4, 5]},
                'estatisticas_clusters': {
                    'cluster_1': {
                        'numeros': [1, 2, 3, 4, 5],
                        'quantidade': 5,
                        'tipo': 'B√°sico',
                        'frequencia_media': 1.0,
                        'frequencia_recente': 0.5,
                        'ultima_aparicao': 5,
                        'intervalo_medio': 10,
                        'score_atraso': 5,
                        'volatilidade': 0.5,
                        'tendencia': 0.5
                    }
                },
                'resumo_clusters': {
                    'cluster_0': {
                        'id': 'Cluster 0',
                        'descricao_curta': 'Cluster b√°sico',
                        'caracteristicas_principais': {
                            'frequencia_media': 1.0,
                            'intervalo_medio': 10,
                            'score_atraso': 5,
                            'volatilidade': 0.5,
                            'tendencia': 0.5
                        },
                        'numeros_exemplos': [1, 2, 3, 4, 5],
                        'todos_numeros_do_cluster': [1, 2, 3, 4, 5],
                        'tamanho': 5,
                        'tipo': 'B√°sico',
                        'recomendacao': 'An√°lise b√°sica',
                        'cor': 'blue'
                    }
                },
                'dados_clustering': [],
                'labels_clusters': [0] * 25
            }
        
        # Preparar dados para clustering (simplificado)
        dados_cluster = []
        for num in range(1, 26):
            # Calcular caracter√≠sticas b√°sicas do n√∫mero
            freq_total = 0
            freq_recente = 0
            ultima_aparicao = 0
            
            for i, (_, row) in enumerate(self.df_validos.iterrows()):
                if num in row[self.colunas_bolas].values:
                    freq_total += 1
                    if i >= len(self.df_validos) - 5:
                        freq_recente += 1
                    ultima_aparicao = i
            
            # Score de atraso (quanto tempo n√£o saiu)
            score_atraso = len(self.df_validos) - ultima_aparicao
            
            # Tend√™ncia (frequ√™ncia recente vs total)
            tendencia = freq_recente / freq_total if freq_total > 0 else 0
            
            dados_cluster.append([
                freq_total,
                freq_recente,
                ultima_aparicao,
                score_atraso,
                tendencia
            ])
        
        # Normalizar dados
        scaler = StandardScaler()
        dados_normalizados = scaler.fit_transform(dados_cluster)
        
        # Aplicar K-means
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(dados_normalizados)
        
        # Organizar resultados
        estatisticas_clusters = {}
        resultados_clusters = {}
        resumo_clusters = {}
        
        for i in range(n_clusters):
            numeros_cluster = [num for num, cluster_id in enumerate(clusters, 1) if cluster_id == i]
            resultados_clusters[f'cluster_{i}'] = numeros_cluster
            
            # Calcular estat√≠sticas do cluster
            freq_media = float(np.mean([dados_cluster[num-1][0] for num in numeros_cluster]))
            freq_recente = float(np.mean([dados_cluster[num-1][1] for num in numeros_cluster]))
            ultima_aparicao = float(np.mean([dados_cluster[num-1][2] for num in numeros_cluster]))
            score_atraso = float(np.mean([dados_cluster[num-1][3] for num in numeros_cluster]))
            tendencia = float(np.mean([dados_cluster[num-1][4] for num in numeros_cluster]))
            
            # Classificar cluster
            tipo = self._classificar_cluster_avancado(
                freq_media, freq_recente, ultima_aparicao, 
                10, score_atraso, 0.5, tendencia
            )
            
            estatisticas_clusters[f'cluster_{i+1}'] = {
                'numeros': numeros_cluster,
                'quantidade': len(numeros_cluster),
                'tipo': tipo,
                'frequencia_media': freq_media,
                'frequencia_recente': freq_recente,
                'ultima_aparicao': ultima_aparicao,
                'intervalo_medio': 10,
                'score_atraso': score_atraso,
                'volatilidade': 0.5,
                'tendencia': tendencia
            }
            
            # Criar resumo detalhado do cluster
            if numeros_cluster:
                resumo_clusters[f'cluster_{i}'] = {
                    'id': f'Cluster {i}',
                    'descricao_curta': f"Cluster com {len(numeros_cluster)} n√∫meros",
                    'caracteristicas_principais': {
                        'frequencia_media': round(freq_media, 2),
                        'intervalo_medio': 10,
                        'score_atraso': round(score_atraso, 2),
                        'volatilidade': 0.5,
                        'tendencia': round(tendencia, 2)
                    },
                    'numeros_exemplos': sorted(numeros_cluster)[:min(len(numeros_cluster), 8)],
                    'todos_numeros_do_cluster': sorted(numeros_cluster),
                    'tamanho': len(numeros_cluster),
                    'tipo': tipo,
                    'recomendacao': 'An√°lise em andamento',
                    'cor': 'blue'
                }
        
        return {
            'clusters': resultados_clusters,
            'estatisticas_clusters': estatisticas_clusters,
            'resumo_clusters': resumo_clusters,
            'dados_clustering': dados_cluster,
            'labels_clusters': clusters.tolist()
        }
    
    def _classificar_cluster_avancado(self, freq_media, freq_recente, ultima_aparicao, 
                                    intervalo_medio, score_atraso, volatilidade, tendencia):
        """Classifica o tipo de cluster baseado em m√∫ltiplas caracter√≠sticas"""
        if freq_media > 15 and freq_recente > 2:
            return "Frequente e Ativo"
        elif freq_media > 10 and score_atraso < 5:
            return "Frequente Recente"
        elif freq_media < 5 and score_atraso > 20:
            return "Raro e Ausente"
        elif volatilidade > 5:
            return "Vol√°til"
        elif tendencia > 0.3:
            return "Em Tend√™ncia"
        elif intervalo_medio < 10:
            return "Ciclo Curto"
        elif intervalo_medio > 20:
            return "Ciclo Longo"
        else:
            return "Regular"
    
    def analise_correlacao_numeros(self):
        """
        Analisa correla√ß√£o entre n√∫meros (SIMPLIFICADA PARA PERFORMANCE)
        
        Returns:
            dict: Resultados da an√°lise de correla√ß√£o
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Para poucos concursos, retornar dados b√°sicos
        if len(self.df_validos) < 10:
            return {
                'correlacoes_positivas': [],
                'correlacoes_negativas': [],
                'correlacao_media': 0.0,
                'total_correlacoes': 0
            }
        
        # Criar matriz de presen√ßa (1 se saiu, 0 se n√£o saiu)
        matriz_presenca = np.zeros((len(self.df_validos), 25))
        
        for i, (_, row) in enumerate(self.df_validos.iterrows()):
            numeros_sorteio = row[self.colunas_bolas].values
            for num in numeros_sorteio:
                if 1 <= num <= 25:
                    matriz_presenca[i, num-1] = 1
        
        # Calcular matriz de correla√ß√£o usando np.corrcoef
        try:
            matriz_correlacao = np.corrcoef(matriz_presenca.T)
            
            # Encontrar pares mais correlacionados (apenas uma amostra)
            pares_correlacionados = []
            
            # Processar apenas uma amostra dos pares para performance
            for i in range(0, 25, 1):
                for j in range(i + 1, 25, 1):
                    if i < matriz_correlacao.shape[0] and j < matriz_correlacao.shape[1]:
                        correlacao = matriz_correlacao[i, j]
                        if not np.isnan(correlacao):
                            pares_correlacionados.append((i + 1, j + 1, correlacao))
            
            # Ordenar por magnitude
            pares_correlacionados.sort(key=lambda x: abs(x[2]), reverse=True)
            
            # Separar correla√ß√µes positivas e negativas
            correlacoes_positivas = [(num1, num2, corr) for num1, num2, corr in pares_correlacionados if corr > 0.1][:10]
            correlacoes_negativas = [(num1, num2, corr) for num1, num2, corr in pares_correlacionados if corr < -0.1][:10]
            
            # Calcular correla√ß√£o m√©dia
            correlacao_media = float(np.mean([corr for _, _, corr in pares_correlacionados])) if pares_correlacionados else 0.0
            
            return {
                'correlacoes_positivas': correlacoes_positivas,
                'correlacoes_negativas': correlacoes_negativas,
                'correlacao_media': correlacao_media,
                'total_correlacoes': len(pares_correlacionados)
            }
            
        except Exception as e:
            return {
                'correlacoes_positivas': [],
                'correlacoes_negativas': [],
                'correlacao_media': 0.0,
                'total_correlacoes': 0
            }
    
    def probabilidades_condicionais(self):
        """
        Calcula probabilidades condicionais entre n√∫meros (SIMPLIFICADA PARA PERFORMANCE)
        
        Returns:
            dict: Resultados das probabilidades condicionais
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Para poucos concursos, retornar dados b√°sicos
        if len(self.df_validos) < 20:
            return {
                'dependencias_fortes': [],
                'dependencias_fracas': [],
                'todas_dependencias': []
            }
        
        # Calcular apenas para os 10 n√∫meros mais frequentes
        frequencias = {}
        for _, row in self.df_validos.iterrows():
            numeros = row[self.colunas_bolas].values
            for num in numeros:
                if 1 <= num <= 25:
                    frequencias[num] = frequencias.get(num, 0) + 1
        
        # Pegar apenas os 10 mais frequentes
        numeros_mais_frequentes = sorted(frequencias.items(), key=lambda x: x[1], reverse=True)[:10]
        numeros_amostra = [num for num, _ in numeros_mais_frequentes]
        
        # Calcular coocorr√™ncias apenas entre esses n√∫meros
        coocorrencias = {}
        for _, row in self.df_validos.iterrows():
            numeros = row[self.colunas_bolas].values
            for num1 in numeros_amostra:
                if num1 in numeros:
                    for num2 in numeros_amostra:
                        if num1 != num2 and num2 in numeros:
                            chave = (min(num1, num2), max(num1, num2))
                            coocorrencias[chave] = coocorrencias.get(chave, 0) + 1
        
        # Calcular probabilidades condicionais
        dependencias = []
        total_concursos = len(self.df_validos)
        
        for (num1, num2), cooc in coocorrencias.items():
            if frequencias.get(num1, 0) > 0:
                p_condicional = cooc / frequencias[num1]
                p_b_base = frequencias.get(num2, 0) / total_concursos
                
                if p_b_base > 0:
                    razao = p_condicional / p_b_base
                    dependencias.append((num1, num2, razao))
        
        # Ordenar por depend√™ncia
        dependencias.sort(key=lambda x: x[2], reverse=True)
        
        # Separar depend√™ncias fortes e fracas
        dependencias_fortes = [dep for dep in dependencias if dep[2] > 1.5][:5]
        dependencias_fracas = [dep for dep in dependencias if dep[2] < 0.7][:5]
        
        return {
            'dependencias_fortes': dependencias_fortes,
            'dependencias_fracas': dependencias_fracas,
            'todas_dependencias': dependencias[:10]
        }

    def calcular_distribuicao_frequencia_numeros(self, df_filtrado):
        """
        Calcula a frequ√™ncia de cada n√∫mero principal (1-25) em um DataFrame filtrado (Lotof√°cil).
        Retorna uma lista de dicion√°rios com {numero: frequencia}.
        
        Args:
            df_filtrado (pd.DataFrame): DataFrame filtrado pela janela temporal
            
        Returns:
            list: Lista de dicion√°rios com n√∫mero e frequ√™ncia
        """
        try:
            if df_filtrado is None or df_filtrado.empty:
                logger.warning("DataFrame filtrado vazio para c√°lculo de distribui√ß√£o")
                return []
            
            # Concatena todas as colunas de bolas e filtra apenas valores v√°lidos (1-25)
            todos_numeros = df_filtrado[self.colunas_bolas].values.flatten()
            
            # Conta a frequ√™ncia de cada n√∫mero no intervalo 1-25
            from collections import Counter
            contagem_numeros = Counter(int(n) for n in todos_numeros 
                                       if pd.notna(n) and 1 <= int(n) <= 25)
            
            # Garante que todos os n√∫meros de 1 a 25 estejam presentes, mesmo com frequ√™ncia 0
            distribuicao = []
            for num in range(1, 26):  # N√∫meros de 1 a 25 (Lotof√°cil)
                distribuicao.append({
                    'numero': num,
                    'frequencia': contagem_numeros.get(num, 0)
                })
            
            # logger.info(f"Distribui√ß√£o calculada para {len(df_filtrado)} concursos")
            return distribuicao
            
        except Exception as e:
            logger.error(f"Erro ao calcular distribui√ß√£o de frequ√™ncia: {e}")
            return []
    
    def executar_analise_completa(self, qtd_concursos=None):
        """
        Executa todas as an√°lises estat√≠sticas avan√ßadas
        
        Args:
            qtd_concursos (int, optional): Quantidade de concursos para an√°lise temporal
            
        Returns:
            dict: Resultados completos de todas as an√°lises
        """
        # logger.info(f"Iniciando an√°lise estat√≠stica avan√ßada completa... (qtd_concursos: {qtd_concursos})")
        
        # Filtrar dados por per√≠odo se especificado
        df_analise = self.df_validos
        if qtd_concursos and qtd_concursos > 0:
            df_analise = self.df_validos.tail(qtd_concursos)
            # logger.info(f"Analisando √∫ltimos {qtd_concursos} concursos ({len(df_analise)} encontrados)")
        
        # Criar inst√¢ncia com dados filtrados (Lotof√°cil)
        analise_temp = AnaliseEstatisticaAvancadaLotofacil(df_analise)
        
        # Ajustar n√∫mero de clusters baseado no tamanho dos dados
        n_clusters = min(5, max(2, len(df_analise) // 5))  # Entre 2 e 5 clusters
        
        resultados = {
            'desvio_padrao_distribuicao': analise_temp.calcular_desvio_padrao_distribuicao(),
            'teste_aleatoriedade': analise_temp.teste_aleatoriedade(),
            'analise_clusters': analise_temp.analise_clusters(n_clusters=n_clusters),
            'analise_correlacao_numeros': analise_temp.analise_correlacao_numeros(),
            'probabilidades_condicionais': analise_temp.probabilidades_condicionais(),
            'distribuicao_numeros': analise_temp.calcular_distribuicao_frequencia_numeros(df_analise)
        }
        
        # Limpar valores NaN antes de retornar
        resultados = limpar_nan_do_dict(resultados)
        
        # logger.info("‚úÖ An√°lise estat√≠stica avan√ßada conclu√≠da!")
        # logger.info(f"üìä Resultados gerados:")
        # logger.info(f"   - Desvio padr√£o: {'‚úÖ' if resultados.get('desvio_padrao_distribuicao') else '‚ùå'}")
        # logger.info(f"   - Probabilidades condicionais: {'‚úÖ' if resultados.get('probabilidades_condicionais') else '‚ùå'}")
        # logger.info(f"   - Distribui√ß√£o n√∫meros: {'‚úÖ' if resultados.get('distribuicao_numeros') else '‚ùå'}")
        
        # Log espec√≠fico para correla√ß√£o (comentado para reduzir polui√ß√£o no terminal)
        # if resultados.get('analise_correlacao_numeros'):
        #     correlacao = resultados['analise_correlacao_numeros']
        #     logger.info(f"üîç Dados de correla√ß√£o detalhados:")
        #     logger.info(f"   - Correla√ß√µes positivas: {len(correlacao.get('correlacoes_positivas', []))}")
        #     logger.info(f"   - Correla√ß√µes negativas: {len(correlacao.get('correlacoes_negativas', []))}")
        #     logger.info(f"   - Correla√ß√£o m√©dia: {correlacao.get('correlacao_media', 0.0):.4f}")
        
        return resultados

def exibir_analise_estatistica_avancada_quina(resultados):
    """
    Exibe os resultados da an√°lise estat√≠stica avan√ßada de forma formatada
    
    Args:
        resultados (dict): Resultados da an√°lise
    """
    print("\n" + "="*80)
    print("üìä AN√ÅLISE ESTAT√çSTICA AVAN√áADA - QUINA")
    print("="*80)
    
    # 1. Desvio Padr√£o
    if 'desvio_padrao_distribuicao' in resultados and resultados['desvio_padrao_distribuicao']:
        print("\nüìà DESVIO PADR√ÉO DA DISTRIBUI√á√ÉO:")
        print("-" * 40)
        stats = resultados['desvio_padrao_distribuicao']['estatisticas_gerais']
        print(f"   M√©dia de frequ√™ncia: {stats['media_frequencia']:.2f}")
        print(f"   Desvio padr√£o: {stats['desvio_padrao']:.2f}")
        print(f"   Vari√¢ncia: {stats['variancia']:.2f}")
        print(f"   Coeficiente de varia√ß√£o: {stats['coeficiente_variacao']:.2f}%")
        
        print("\n   üî• N√∫meros mais vari√°veis:")
        for num, freq in resultados['desvio_padrao_distribuicao']['numeros_mais_variaveis'][:5]:
            print(f"      N√∫mero {num}: {freq} vezes")
    
    # 2. Teste de Aleatoriedade
    if 'teste_aleatoriedade' in resultados and resultados['teste_aleatoriedade']:
        print("\nüé≤ TESTE DE ALEATORIEDADE:")
        print("-" * 40)
        
        chi2 = resultados['teste_aleatoriedade']['teste_chi_quadrado']
        print(f"   Teste Chi-quadrado:")
        print(f"      Valor: {chi2['chi2']:.4f}")
        print(f"      P-valor: {chi2['p_value']:.4f}")
        print(f"      Resultado: {chi2['interpretacao']}")
        
        paridade = resultados['teste_aleatoriedade']['teste_paridade']
        print(f"   Teste de Paridade:")
        print(f"      M√©dia de pares: {paridade['media_pares']:.2f} (esperado: 2.5)")
        print(f"      Aleat√≥rio: {'Sim' if paridade['aleatorio_paridade'] else 'N√£o'}")
    
    # 3. An√°lise de Clusters
    if 'analise_clusters' in resultados and resultados['analise_clusters']:
        print("\nüîó AN√ÅLISE DE CLUSTERS:")
        print("-" * 40)
        
        for cluster_id, info in resultados['analise_clusters']['estatisticas_clusters'].items():
            print(f"   {cluster_id.upper()} ({info['tipo']}):")
            print(f"      N√∫meros: {info['numeros']}")
            print(f"      Quantidade: {info['quantidade']}")
            print(f"      Frequ√™ncia m√©dia: {info['frequencia_media']:.2f}")
    
    # 4. Correla√ß√£o
    if 'analise_correlacao_numeros' in resultados and resultados['analise_correlacao_numeros']:
        print("\nüìà CORRELA√á√ÉO ENTRE N√öMEROS:")
        print("-" * 40)
        
        print("   üîó Correla√ß√µes positivas (tendem a sair juntos):")
        for num1, num2, corr in resultados['analise_correlacao_numeros']['correlacoes_positivas'][:5]:
            print(f"      {num1} ‚Üî {num2}: {corr:.3f}")
        
        print("   üîÑ Correla√ß√µes negativas (raramente saem juntos):")
        for num1, num2, corr in resultados['analise_correlacao_numeros']['correlacoes_negativas'][:5]:
            print(f"      {num1} ‚Üî {num2}: {corr:.3f}")
    
    # 5. Probabilidades Condicionais
    if 'probabilidades_condicionais' in resultados and resultados['probabilidades_condicionais']:
        print("\nüéØ PROBABILIDADES CONDICIONAIS:")
        print("-" * 40)
        
        print("   üí™ Depend√™ncias mais fortes:")
        for num1, num2, dep in resultados['probabilidades_condicionais']['dependencias_fortes'][:10]:
            print(f"      {num1} ‚Üí {num2}: {dep:.2f}x mais prov√°vel")

def realizar_analise_estatistica_avancada_lotofacil(df_lotofacil=None, qtd_concursos=50):
    """
    Fun√ß√£o wrapper para an√°lise estat√≠stica avan√ßada da Lotof√°cil.
    Esta fun√ß√£o padroniza o carregamento de dados e filtragem antes de chamar
    a fun√ß√£o principal de an√°lise.
    
    Args:
        df_lotofacil (pd.DataFrame, optional): DataFrame com dados da Lotof√°cil
        qtd_concursos (int): Quantidade de √∫ltimos concursos a analisar (padr√£o: 50)
    
    Returns:
        dict: Resultado da an√°lise estat√≠stica avan√ßada
    """
    try:
        from funcoes.lotofacil.LotofacilFuncaCarregaDadosExcel import carregar_dados_lotofacil
        
        # Carregar dados se n√£o fornecidos
        if df_lotofacil is None:
            df_lotofacil = carregar_dados_lotofacil()
            
        if df_lotofacil is None or df_lotofacil.empty:
            return {'erro': 'Dados da Lotof√°cil n√£o dispon√≠veis'}
        
        # Filtrar para os √∫ltimos N concursos se especificado
        if qtd_concursos is not None and qtd_concursos > 0:
            df_filtrado = df_lotofacil.tail(qtd_concursos).copy()
        else:
            df_filtrado = df_lotofacil.copy()
        
        # Criar inst√¢ncia da an√°lise
        analise = AnaliseEstatisticaAvancadaLotofacil(df_filtrado)
        
        # Executar an√°lise completa
        resultado_completo = analise.executar_analise_completa()
        
        if not resultado_completo:
            print("‚ùå Erro: An√°lise retornou resultado vazio")
            return {'erro': 'An√°lise n√£o produziu resultados'}
        
        print(f"‚úÖ An√°lise estat√≠stica avan√ßada da Lotof√°cil conclu√≠da com sucesso!")
        return resultado_completo
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise estat√≠stica avan√ßada da Lotof√°cil: {e}")
        import traceback
        traceback.print_exc()
        return {'erro': f'Erro interno: {str(e)}'}

"""
Nota: bloco de execu√ß√£o direta removido deste m√≥dulo.
Scripts de exemplo/diagn√≥stico foram movidos para scripts/diagnostico/.
"""