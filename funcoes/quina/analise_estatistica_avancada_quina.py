#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AN√ÅLISE ESTAT√çSTICA AVAN√áADA - QUINA
====================================

M√≥dulo contendo an√°lises estat√≠sticas avan√ßadas para a Quina:
1. üìä Desvio padr√£o: variabilidade na distribui√ß√£o
2. üé≤ Teste de aleatoriedade: verificar se os sorteios s√£o realmente aleat√≥rios
3. üîó An√°lise de clusters: agrupamentos de n√∫meros
4. üìà Correla√ß√£o entre n√∫meros: quais tendem a sair juntos
5. üéØ Probabilidades condicionais: chance de um n√∫mero sair dado que outro saiu

Autor: Sistema IA Quina
Data: 2024
Vers√£o: An√°lises Estat√≠sticas Avan√ßadas
"""

import numpy as np
import pandas as pd
from scipy import stats
from scipy.stats import chi2_contingency, pearsonr, spearmanr
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def limpar_nan_do_dict(d):
    """Remove valores NaN de dicion√°rios aninhados"""
    if isinstance(d, dict):
        return {k: limpar_nan_do_dict(v) for k, v in d.items()}
    elif isinstance(d, list):
        return [limpar_nan_do_dict(v) for v in d]
    elif isinstance(d, (int, float)):
        if np.isnan(d):
            return 0.0
        return d
    else:
        return d

class AnaliseEstatisticaAvancadaQuina:
    """
    Classe para an√°lises estat√≠sticas avan√ßadas da Quina
    """
    
    def __init__(self, df_quina):
        """
        Inicializa a an√°lise com os dados da Quina
        
        Args:
            df_quina (pd.DataFrame): DataFrame com os dados dos sorteios
        """
        self.df = df_quina
        self.colunas_bolas = ['Bola1', 'Bola2', 'Bola3', 'Bola4', 'Bola5']
        self._preparar_dados()
    
    def _preparar_dados(self):
        """Prepara e valida os dados para an√°lise"""
        if self.df is None or self.df.empty:
            logger.error("DataFrame vazio ou None")
            return
        
        # Limpar e validar dados (Quina: apenas n√∫meros, sem trevos)
        self.df_limpo = self.df.dropna(subset=self.colunas_bolas).copy()
        
        # Converter para num√©rico
        for col in self.colunas_bolas:
            self.df_limpo[col] = pd.to_numeric(self.df_limpo[col], errors='coerce').astype('Int64')
        
        # Filtrar dados v√°lidos (Quina: apenas n√∫meros 1-80, sem trevos)
        mask_bolas = self.df_limpo[self.colunas_bolas].notna().all(axis=1) & \
                    (self.df_limpo[self.colunas_bolas] >= 1).all(axis=1) & \
                    (self.df_limpo[self.colunas_bolas] <= 80).all(axis=1)
        
        self.df_validos = self.df_limpo[mask_bolas]
        
        if self.df_validos.empty:
            logger.error("Nenhum dado v√°lido encontrado ap√≥s limpeza")
            return
        
        logger.info(f"Dados preparados: {len(self.df_validos)} concursos v√°lidos")
    
    def calcular_desvio_padrao_distribuicao(self):
        """
        Calcula o desvio padr√£o da distribui√ß√£o dos n√∫meros
        
        Returns:
            dict: Estat√≠sticas de desvio padr√£o
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Calcular frequ√™ncia de cada n√∫mero (1-80 para Quina)
        frequencias = {}
        for num in range(1, 81):
            count = 0
            for _, row in self.df_validos.iterrows():
                if num in row[self.colunas_bolas].values:
                    count += 1
            frequencias[num] = count
        
        # Calcular estat√≠sticas
        valores = list(frequencias.values())
        media = np.mean(valores)
        desvio_padrao = np.std(valores)
        variancia = np.var(valores)
        coeficiente_variacao = (desvio_padrao / media) * 100 if media > 0 else 0
        
        # Ordenar n√∫meros por variabilidade
        numeros_variaveis = sorted(frequencias.items(), key=lambda x: x[1], reverse=True)
        
        return {
            'estatisticas_gerais': {
                'media_frequencia': media,
                'desvio_padrao': desvio_padrao,
                'variancia': variancia,
                'coeficiente_variacao': coeficiente_variacao
            },
            'numeros_mais_variaveis': numeros_variaveis,
            'frequencias_completas': frequencias
        }
    
    def teste_aleatoriedade(self):
        """
        Testa se os sorteios s√£o realmente aleat√≥rios
        
        Returns:
            dict: Resultados dos testes de aleatoriedade
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Teste Chi-quadrado para uniformidade
        frequencias = []
        for num in range(1, 81):
            count = 0
            for _, row in self.df_validos.iterrows():
                if num in row[self.colunas_bolas].values:
                    count += 1
            frequencias.append(count)
        
        # Valor esperado para cada n√∫mero (uniforme)
        total_sorteios = len(self.df_validos)
        esperado = (total_sorteios * 5) / 80  # 5 n√∫meros por sorteio, 80 n√∫meros poss√≠veis
        
        # Teste Chi-quadrado
        chi2_stat, p_value = stats.chisquare(frequencias, [esperado] * 80)
        
        # Interpreta√ß√£o
        if p_value < 0.05:
            interpretacao = "N√£o aleat√≥rio (p < 0.05)"
        else:
            interpretacao = "Aleat√≥rio (p >= 0.05)"
        
        # Teste de paridade (pares vs √≠mpares)
        pares_por_sorteio = []
        for _, row in self.df_validos.iterrows():
            numeros = row[self.colunas_bolas].values
            pares = sum(1 for num in numeros if num % 2 == 0)
            pares_por_sorteio.append(pares)
        
        media_pares = np.mean(pares_por_sorteio)
        # Em 5 n√∫meros, esperamos em m√©dia 2.5 pares
        aleatorio_paridade = abs(media_pares - 2.5) < 0.5
        
        return {
            'teste_chi_quadrado': {
                'chi2': chi2_stat,
                'p_value': p_value,
                'interpretacao': interpretacao
            },
                'teste_paridade': {
                'media_pares': media_pares,
                'aleatorio_paridade': aleatorio_paridade
            }
        }
    
    def analise_clusters(self, n_clusters=5):
        """
        An√°lise de clusters para agrupar n√∫meros similares
        
        Args:
            n_clusters (int): N√∫mero de clusters desejados
            
        Returns:
            dict: Resultados da an√°lise de clusters
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Preparar dados para clustering
        dados_cluster = []
        for num in range(1, 81):
            # Calcular caracter√≠sticas do n√∫mero
            freq_total = 0
            freq_recente = 0
            ultima_aparicao = 0
            intervalos = []
            
            for i, (_, row) in enumerate(self.df_validos.iterrows()):
                if num in row[self.colunas_bolas].values:
                    freq_total += 1
                    if i >= len(self.df_validos) - 10:  # √öltimos 10 concursos
                        freq_recente += 1
                    ultima_aparicao = i
            
            # Calcular intervalo m√©dio
            if freq_total > 1:
                aparicoes = []
                for i, (_, row) in enumerate(self.df_validos.iterrows()):
                    if num in row[self.colunas_bolas].values:
                        aparicoes.append(i)
                
                for j in range(1, len(aparicoes)):
                    intervalos.append(aparicoes[j] - aparicoes[j-1])
                
                intervalo_medio = np.mean(intervalos) if intervalos else 0
            else:
                intervalo_medio = len(self.df_validos)
            
            # Score de atraso (quanto tempo n√£o saiu)
            score_atraso = len(self.df_validos) - ultima_aparicao
            
            # Volatilidade (desvio padr√£o dos intervalos)
            volatilidade = np.std(intervalos) if len(intervalos) > 1 else 0
            
            # Tend√™ncia (frequ√™ncia recente vs total)
            tendencia = freq_recente / freq_total if freq_total > 0 else 0
            
            dados_cluster.append([
                freq_total,
                freq_recente,
                ultima_aparicao,
                intervalo_medio,
                score_atraso,
                volatilidade,
                tendencia
            ])
        
        # Normalizar dados
        scaler = StandardScaler()
        dados_normalizados = scaler.fit_transform(dados_cluster)
        
        # Aplicar K-means
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(dados_normalizados)
        
        # Organizar resultados
        estatisticas_clusters = {}
        for i in range(n_clusters):
            numeros_cluster = [num for num, cluster_id in enumerate(clusters, 1) if cluster_id == i]
            
            # Calcular estat√≠sticas do cluster
            freq_media = np.mean([dados_cluster[num-1][0] for num in numeros_cluster])
            freq_recente = np.mean([dados_cluster[num-1][1] for num in numeros_cluster])
            ultima_aparicao = np.mean([dados_cluster[num-1][2] for num in numeros_cluster])
            intervalo_medio = np.mean([dados_cluster[num-1][3] for num in numeros_cluster])
            score_atraso = np.mean([dados_cluster[num-1][4] for num in numeros_cluster])
            volatilidade = np.mean([dados_cluster[num-1][5] for num in numeros_cluster])
            tendencia = np.mean([dados_cluster[num-1][6] for num in numeros_cluster])
            
            # Classificar cluster
            tipo = self._classificar_cluster_avancado(
                freq_media, freq_recente, ultima_aparicao, 
                intervalo_medio, score_atraso, volatilidade, tendencia
            )
            
            estatisticas_clusters[f'cluster_{i+1}'] = {
                    'numeros': numeros_cluster,
                'quantidade': len(numeros_cluster),
                'tipo': tipo,
                'frequencia_media': freq_media,
                'frequencia_recente': freq_recente,
                'ultima_aparicao': ultima_aparicao,
                'intervalo_medio': intervalo_medio,
                'score_atraso': score_atraso,
                'volatilidade': volatilidade,
                'tendencia': tendencia
                }
        
        return {
            'estatisticas_clusters': estatisticas_clusters,
            'dados_clustering': dados_cluster,
            'labels_clusters': clusters.tolist()
        }
    
    def _classificar_cluster_avancado(self, freq_media, freq_recente, ultima_aparicao, 
                                    intervalo_medio, score_atraso, volatilidade, tendencia):
        """Classifica o tipo de cluster baseado em m√∫ltiplas caracter√≠sticas"""
        if freq_media > 15 and freq_recente > 2:
            return "Frequente e Ativo"
        elif freq_media > 10 and score_atraso < 5:
            return "Frequente Recente"
        elif freq_media < 5 and score_atraso > 20:
            return "Raro e Ausente"
        elif volatilidade > 5:
            return "Vol√°til"
        elif tendencia > 0.3:
            return "Em Tend√™ncia"
        elif intervalo_medio < 10:
            return "Ciclo Curto"
        elif intervalo_medio > 20:
            return "Ciclo Longo"
        else:
            return "Regular"
    
    def analise_correlacao_numeros(self):
        """
        Analisa correla√ß√£o entre n√∫meros
        
        Returns:
            dict: Resultados da an√°lise de correla√ß√£o
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Criar matriz de presen√ßa (1 se saiu, 0 se n√£o saiu)
        matriz_presenca = np.zeros((len(self.df_validos), 80))
        
        for i, (_, row) in enumerate(self.df_validos.iterrows()):
            numeros_sorteio = row[self.colunas_bolas].values
            for num in numeros_sorteio:
                if 1 <= num <= 80:
                    matriz_presenca[i, num-1] = 1
        
        # Calcular correla√ß√µes
        correlacoes = []
        for i in range(80):
            for j in range(i+1, 80):
                corr, p_value = pearsonr(matriz_presenca[:, i], matriz_presenca[:, j])
                if not np.isnan(corr):
                    correlacoes.append((i+1, j+1, corr, p_value))
        
        # Separar correla√ß√µes positivas e negativas
        correlacoes_positivas = [(num1, num2, corr) for num1, num2, corr, p in correlacoes if corr > 0.1 and p < 0.05]
        correlacoes_negativas = [(num1, num2, corr) for num1, num2, corr, p in correlacoes if corr < -0.1 and p < 0.05]
        
        # Ordenar por magnitude
        correlacoes_positivas.sort(key=lambda x: x[2], reverse=True)
        correlacoes_negativas.sort(key=lambda x: x[2])
        
        # Calcular correla√ß√£o m√©dia
        correlacao_media = np.mean([corr for _, _, corr, _ in correlacoes])
        
        return {
            'correlacoes_positivas': correlacoes_positivas[:20],
            'correlacoes_negativas': correlacoes_negativas[:20],
            'correlacao_media': correlacao_media,
            'total_correlacoes': len(correlacoes)
        }
    
    def probabilidades_condicionais(self):
        """
        Calcula probabilidades condicionais entre n√∫meros
        
        Returns:
            dict: Resultados das probabilidades condicionais
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Calcular probabilidades condicionais
        dependencias = []
        
        for num1 in range(1, 81):
            for num2 in range(1, 81):
                if num1 != num2:
                    # P(B|A) = P(A‚à©B) / P(A)
                    p_a = 0  # Probabilidade de A sair
                    p_ab = 0  # Probabilidade de A e B sa√≠rem juntos
                    
                    for _, row in self.df_validos.iterrows():
                        numeros = row[self.colunas_bolas].values
                        if num1 in numeros:
                            p_a += 1
                            if num2 in numeros:
                                p_ab += 1
                    
                    if p_a > 0:
                        p_condicional = p_ab / p_a
                        # Normalizar pela probabilidade base de B
                        p_b_base = sum(1 for _, row in self.df_validos.iterrows() if num2 in row[self.colunas_bolas].values) / len(self.df_validos)
                        
                        if p_b_base > 0:
                            razao = p_condicional / p_b_base
                            dependencias.append((num1, num2, razao))
        
        # Ordenar por depend√™ncia
        dependencias.sort(key=lambda x: x[2], reverse=True)
        
        # Separar depend√™ncias fortes e fracas
        dependencias_fortes = [dep for dep in dependencias if dep[2] > 1.5]
        dependencias_fracas = [dep for dep in dependencias if dep[2] < 0.7]
        
        return {
            'dependencias_fortes': dependencias_fortes[:20],
            'dependencias_fracas': dependencias_fracas[:20],
            'todas_dependencias': dependencias[:50]
        }

    def calcular_distribuicao_frequencia_numeros(self, df_filtrado):
        """
        Calcula a distribui√ß√£o de frequ√™ncia dos n√∫meros
        
        Args:
            df_filtrado (pd.DataFrame): DataFrame filtrado para an√°lise
            
        Returns:
            dict: Distribui√ß√£o de frequ√™ncia
        """
        if df_filtrado is None or df_filtrado.empty:
            return {}
        
        # Calcular frequ√™ncia de cada n√∫mero
        frequencias = {}
        for num in range(1, 81):
            count = 0
            for _, row in df_filtrado.iterrows():
                if num in row[self.colunas_bolas].values:
                    count += 1
            frequencias[num] = count
        
        # Estat√≠sticas
        valores = list(frequencias.values())
        media = np.mean(valores)
        mediana = np.median(valores)
        desvio = np.std(valores)
        
        return {
            'frequencias': frequencias,
            'estatisticas': {
                'media': media,
                'mediana': mediana,
                'desvio_padrao': desvio,
                'minimo': min(valores),
                'maximo': max(valores)
            },
            'numeros_mais_frequentes': sorted(frequencias.items(), key=lambda x: x[1], reverse=True)[:10],
            'numeros_menos_frequentes': sorted(frequencias.items(), key=lambda x: x[1])[:10]
        }
    
    def executar_analise_completa(self, qtd_concursos=None):
        """
        Executa todas as an√°lises estat√≠sticas avan√ßadas
        
        Args:
            qtd_concursos (int, optional): Quantidade de concursos para an√°lise temporal
            
        Returns:
            dict: Resultados completos de todas as an√°lises
        """
        logger.info(f"Iniciando an√°lise estat√≠stica avan√ßada completa... (qtd_concursos: {qtd_concursos})")
        
        # Filtrar dados por per√≠odo se especificado
        df_analise = self.df_validos
        if qtd_concursos and qtd_concursos > 0:
            df_analise = self.df_validos.tail(qtd_concursos)
            logger.info(f"Analisando √∫ltimos {qtd_concursos} concursos ({len(df_analise)} encontrados)")
        
        # Criar inst√¢ncia tempor√°ria com dados filtrados
        analise_temp = AnaliseEstatisticaAvancadaQuina(df_analise)
        
        # Ajustar n√∫mero de clusters baseado no tamanho dos dados
        n_clusters = min(5, max(2, len(df_analise) // 5))  # Entre 2 e 5 clusters
        
        resultados = {
            'desvio_padrao_distribuicao': analise_temp.calcular_desvio_padrao_distribuicao(),
            'teste_aleatoriedade': analise_temp.teste_aleatoriedade(),
            'analise_clusters': analise_temp.analise_clusters(n_clusters=n_clusters),
            'analise_correlacao_numeros': analise_temp.analise_correlacao_numeros(),
            'probabilidades_condicionais': analise_temp.probabilidades_condicionais(),
            'distribuicao_numeros': self.calcular_distribuicao_frequencia_numeros(df_analise)
        }
        
        # Limpar valores NaN antes de retornar
        resultados = limpar_nan_do_dict(resultados)
        
        logger.info("‚úÖ An√°lise estat√≠stica avan√ßada conclu√≠da!")
        logger.info(f"üìä Resultados gerados:")
        logger.info(f"   - Desvio padr√£o: {'‚úÖ' if resultados.get('desvio_padrao_distribuicao') else '‚ùå'}")
        logger.info(f"   - Teste aleatoriedade: {'‚úÖ' if resultados.get('teste_aleatoriedade') else '‚ùå'}")
        logger.info(f"   - An√°lise clusters: {'‚úÖ' if resultados.get('analise_clusters') else '‚ùå'}")
        logger.info(f"   - Correla√ß√£o n√∫meros: {'‚úÖ' if resultados.get('analise_correlacao_numeros') else '‚ùå'}")
        logger.info(f"   - Probabilidades condicionais: {'‚úÖ' if resultados.get('probabilidades_condicionais') else '‚ùå'}")
        logger.info(f"   - Distribui√ß√£o n√∫meros: {'‚úÖ' if resultados.get('distribuicao_numeros') else '‚ùå'}")
        
        # Log espec√≠fico para correla√ß√£o
        if resultados.get('analise_correlacao_numeros'):
            correlacao = resultados['analise_correlacao_numeros']
            logger.info(f"üîç Dados de correla√ß√£o detalhados:")
            logger.info(f"   - Correla√ß√µes positivas: {len(correlacao.get('correlacoes_positivas', []))}")
            logger.info(f"   - Correla√ß√µes negativas: {len(correlacao.get('correlacoes_negativas', []))}")
            logger.info(f"   - Correla√ß√£o m√©dia: {correlacao.get('correlacao_media', 0.0):.4f}")
        
        return resultados

def exibir_analise_estatistica_avancada_quina(resultados):
    """
    Exibe os resultados da an√°lise estat√≠stica avan√ßada de forma formatada
    
    Args:
        resultados (dict): Resultados da an√°lise
    """
    print("\n" + "="*80)
    print("üìä AN√ÅLISE ESTAT√çSTICA AVAN√áADA - QUINA")
    print("="*80)
    
    # 1. Desvio Padr√£o
    if 'desvio_padrao_distribuicao' in resultados and resultados['desvio_padrao_distribuicao']:
        print("\nüìà DESVIO PADR√ÉO DA DISTRIBUI√á√ÉO:")
        print("-" * 40)
        stats = resultados['desvio_padrao_distribuicao']['estatisticas_gerais']
        print(f"   M√©dia de frequ√™ncia: {stats['media_frequencia']:.2f}")
        print(f"   Desvio padr√£o: {stats['desvio_padrao']:.2f}")
        print(f"   Vari√¢ncia: {stats['variancia']:.2f}")
        print(f"   Coeficiente de varia√ß√£o: {stats['coeficiente_variacao']:.2f}%")
        
        print("\n   üî• N√∫meros mais vari√°veis:")
        for num, freq in resultados['desvio_padrao_distribuicao']['numeros_mais_variaveis'][:5]:
            print(f"      N√∫mero {num}: {freq} vezes")
    
    # 2. Teste de Aleatoriedade
    if 'teste_aleatoriedade' in resultados and resultados['teste_aleatoriedade']:
        print("\nüé≤ TESTE DE ALEATORIEDADE:")
        print("-" * 40)
        
        chi2 = resultados['teste_aleatoriedade']['teste_chi_quadrado']
        print(f"   Teste Chi-quadrado:")
        print(f"      Valor: {chi2['chi2']:.4f}")
        print(f"      P-valor: {chi2['p_value']:.4f}")
        print(f"      Resultado: {chi2['interpretacao']}")
        
        paridade = resultados['teste_aleatoriedade']['teste_paridade']
        print(f"   Teste de Paridade:")
        print(f"      M√©dia de pares: {paridade['media_pares']:.2f} (esperado: 2.5)")
        print(f"      Aleat√≥rio: {'Sim' if paridade['aleatorio_paridade'] else 'N√£o'}")
    
    # 3. An√°lise de Clusters
    if 'analise_clusters' in resultados and resultados['analise_clusters']:
        print("\nüîó AN√ÅLISE DE CLUSTERS:")
        print("-" * 40)
        
        for cluster_id, info in resultados['analise_clusters']['estatisticas_clusters'].items():
            print(f"   {cluster_id.upper()} ({info['tipo']}):")
            print(f"      N√∫meros: {info['numeros']}")
            print(f"      Quantidade: {info['quantidade']}")
            print(f"      Frequ√™ncia m√©dia: {info['frequencia_media']:.2f}")
    
    # 4. Correla√ß√£o
    if 'analise_correlacao_numeros' in resultados and resultados['analise_correlacao_numeros']:
        print("\nüìà CORRELA√á√ÉO ENTRE N√öMEROS:")
        print("-" * 40)
        
        print("   üîó Correla√ß√µes positivas (tendem a sair juntos):")
        for num1, num2, corr in resultados['analise_correlacao_numeros']['correlacoes_positivas'][:5]:
            print(f"      {num1} ‚Üî {num2}: {corr:.3f}")
        
        print("   üîÑ Correla√ß√µes negativas (raramente saem juntos):")
        for num1, num2, corr in resultados['analise_correlacao_numeros']['correlacoes_negativas'][:5]:
            print(f"      {num1} ‚Üî {num2}: {corr:.3f}")
    
    # 5. Probabilidades Condicionais
    if 'probabilidades_condicionais' in resultados and resultados['probabilidades_condicionais']:
        print("\nüéØ PROBABILIDADES CONDICIONAIS:")
        print("-" * 40)
        
        print("   üí™ Depend√™ncias mais fortes:")
        for num1, num2, dep in resultados['probabilidades_condicionais']['dependencias_fortes'][:10]:
            print(f"      {num1} ‚Üí {num2}: {dep:.2f}x mais prov√°vel")

def realizar_analise_estatistica_avancada_quina(df_quina=None, qtd_concursos=50):
    """
    Fun√ß√£o wrapper para an√°lise estat√≠stica avan√ßada da Quina.
    Esta fun√ß√£o padroniza o carregamento de dados e filtragem antes de chamar
    a fun√ß√£o principal de an√°lise.
    
    Args:
        df_quina (pd.DataFrame, optional): DataFrame com dados da Quina
        qtd_concursos (int): Quantidade de √∫ltimos concursos a analisar (padr√£o: 50)
    
    Returns:
        dict: Resultado da an√°lise estat√≠stica avan√ßada
    """
    try:
        from funcoes.quina.QuinaFuncaCarregaDadosExcel_quina import carregar_dados_quina
        
        # Carregar dados se n√£o fornecidos
        if df_quina is None:
            print("üîÑ Carregando dados da Quina...")
            df_quina = carregar_dados_quina()
            
        if df_quina is None or df_quina.empty:
            print("‚ùå Erro: N√£o foi poss√≠vel carregar os dados da Quina")
            return {'erro': 'Dados da Quina n√£o dispon√≠veis'}
        
        # Filtrar para os √∫ltimos N concursos se especificado
        if qtd_concursos is not None and qtd_concursos > 0:
            df_filtrado = df_quina.tail(qtd_concursos).copy()
            print(f"üîß Filtrando para os √∫ltimos {qtd_concursos} concursos (de {len(df_quina)} dispon√≠veis)")
        else:
            df_filtrado = df_quina.copy()
        
        # Criar inst√¢ncia da an√°lise
        analise = AnaliseEstatisticaAvancadaQuina(df_filtrado)
        
        # Executar an√°lise completa
        resultado_completo = analise.executar_analise_completa()
        
        if not resultado_completo:
            print("‚ùå Erro: An√°lise retornou resultado vazio")
            return {'erro': 'An√°lise n√£o produziu resultados'}
        
        print(f"‚úÖ An√°lise estat√≠stica avan√ßada da Quina conclu√≠da com sucesso!")
        return resultado_completo
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise estat√≠stica avan√ßada da Quina: {e}")
        import traceback
        traceback.print_exc()
        return {'erro': f'Erro interno: {str(e)}'}

# Exemplo de uso
if __name__ == "__main__":
    try:
        from funcoes.quina.QuinaFuncaCarregaDadosExcel_quina import carregar_dados_quina
        
        print("üìä AN√ÅLISE ESTAT√çSTICA AVAN√áADA - QUINA")
        print("="*80)
        
        df_quina = carregar_dados_quina()
        
        if df_quina is not None and not df_quina.empty:
            # Criar inst√¢ncia da an√°lise
            analise = AnaliseEstatisticaAvancadaQuina(df_quina)
            
            # Executar an√°lise completa
            resultados = analise.executar_analise_completa()
            
            # Exibir resultados
            exibir_analise_estatistica_avancada_quina(resultados)
            
        else:
            print("‚ùå N√£o foi poss√≠vel carregar os dados da Quina")
            
    except ImportError:
        print("‚ö†Ô∏è  M√≥dulo de carregamento n√£o encontrado. Usando dados de exemplo...")
        
        # Dados de exemplo para teste
        dados_exemplo = [
            [1, 1, 3, 7, 15, 23],
            [2, 13, 16, 35, 41, 42],
            [3, 1, 9, 17, 30, 31],
            [4, 6, 23, 25, 33, 34],
            [5, 6, 16, 21, 24, 26]
        ]
        df_exemplo = pd.DataFrame(dados_exemplo, columns=['Concurso', 'Bola1', 'Bola2', 'Bola3', 'Bola4', 'Bola5'])
        
        analise = AnaliseEstatisticaAvancadaQuina(df_exemplo)
        resultados = analise.executar_analise_completa()
        exibir_analise_estatistica_avancada_quina(resultados) 