#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AN√ÅLISE ESTAT√çSTICA AVAN√áADA - +MILION√ÅRIA
==========================================

M√≥dulo contendo an√°lises estat√≠sticas avan√ßadas para a +Milion√°ria:
1. üìä Desvio padr√£o: variabilidade na distribui√ß√£o
2. üé≤ Teste de aleatoriedade: verificar se os sorteios s√£o realmente aleat√≥rios
3. üîó An√°lise de clusters: agrupamentos de n√∫meros
4. üìà Correla√ß√£o entre n√∫meros: quais tendem a sair juntos
5. üéØ Probabilidades condicionais: chance de um n√∫mero sair dado que outro saiu

Autor: Sistema IA +Milion√°ria
Data: 2024
Vers√£o: An√°lises Estat√≠sticas Avan√ßadas
"""

import numpy as np
import pandas as pd
from scipy import stats
from scipy.stats import chi2_contingency, pearsonr, spearmanr
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def limpar_nan_do_dict(d):
    """Remove valores NaN de dicion√°rios aninhados"""
    if isinstance(d, dict):
        return {k: limpar_nan_do_dict(v) for k, v in d.items()}
    elif isinstance(d, list):
        return [limpar_nan_do_dict(v) for v in d]
    elif isinstance(d, (int, float)):
        if np.isnan(d):
            return 0.0
        return d
    else:
        return d

class AnaliseEstatisticaAvancada:
    """
    Classe para an√°lises estat√≠sticas avan√ßadas da +Milion√°ria
    """
    
    def __init__(self, df_milionaria):
        """
        Inicializa a an√°lise com os dados da +Milion√°ria
        
        Args:
            df_milionaria (pd.DataFrame): DataFrame com os dados dos sorteios
        """
        self.df = df_milionaria
        self.colunas_bolas = ['Bola1', 'Bola2', 'Bola3', 'Bola4', 'Bola5', 'Bola6']
        self.colunas_trevos = ['Trevo1', 'Trevo2']
        self._preparar_dados()
    
    def _preparar_dados(self):
        """Prepara e valida os dados para an√°lise"""
        if self.df is None or self.df.empty:
            logger.error("DataFrame vazio ou None")
            return
        
        # Limpar e validar dados
        self.df_limpo = self.df.dropna(subset=self.colunas_bolas + self.colunas_trevos).copy()
        
        # Converter para num√©rico
        for col in self.colunas_bolas + self.colunas_trevos:
            self.df_limpo[col] = pd.to_numeric(self.df_limpo[col], errors='coerce').astype('Int64')
        
        # Filtrar dados v√°lidos
        mask_bolas = self.df_limpo[self.colunas_bolas].notna().all(axis=1) & \
                    (self.df_limpo[self.colunas_bolas] >= 1).all(axis=1) & \
                    (self.df_limpo[self.colunas_bolas] <= 50).all(axis=1)
        
        mask_trevos = self.df_limpo[self.colunas_trevos].notna().all(axis=1) & \
                     (self.df_limpo[self.colunas_trevos] >= 1).all(axis=1) & \
                     (self.df_limpo[self.colunas_trevos] <= 6).all(axis=1)
        
        self.df_validos = self.df_limpo[mask_bolas & mask_trevos]
        
        if self.df_validos.empty:
            logger.error("Nenhum dado v√°lido encontrado ap√≥s limpeza")
            return
        
        logger.info(f"Dados preparados: {len(self.df_validos)} concursos v√°lidos")
    
    def calcular_desvio_padrao_distribuicao(self):
        """
        Calcula o desvio padr√£o da distribui√ß√£o dos n√∫meros
        
        Returns:
            dict: Estat√≠sticas de desvio padr√£o
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Verificar se h√° dados suficientes
        if len(self.df_validos) < 1:
            return {
                'estatisticas_gerais': {
                    'media_frequencia': 0.0,
                    'desvio_padrao': 0.0,
                    'variancia': 0.0,
                    'coeficiente_variacao': 0.0,
                    'total_concursos': 0
                },
                'numeros_mais_variaveis': [],
                'numeros_menos_variaveis': [],
                'frequencia_completa': {}
            }
        
        # Extrair todos os n√∫meros sorteados
        todos_numeros = []
        for _, row in self.df_validos.iterrows():
            numeros_concurso = [row[col] for col in self.colunas_bolas if pd.notna(row[col])]
            todos_numeros.extend(numeros_concurso)
        
        # Calcular frequ√™ncia de cada n√∫mero
        frequencia_numeros = Counter(todos_numeros)
        
        # Garantir que todos os n√∫meros de 1 a 50 tenham uma frequ√™ncia (mesmo que 0)
        for numero in range(1, 51):
            if numero not in frequencia_numeros:
                frequencia_numeros[numero] = 0
        
        # Calcular estat√≠sticas
        valores = list(frequencia_numeros.values())
        if not valores:
            return {
                'estatisticas_gerais': {
                    'media_frequencia': 0.0,
                    'desvio_padrao': 0.0,
                    'variancia': 0.0,
                    'coeficiente_variacao': 0.0,
                    'total_concursos': 0
                },
                'numeros_mais_variaveis': [],
                'numeros_menos_variaveis': [],
                'frequencia_completa': {}
            }
        
        media = np.mean(valores)
        desvio_padrao = np.std(valores)
        variancia = np.var(valores)
        coeficiente_variacao = (desvio_padrao / media) * 100 if media > 0 else 0
        
        # Converter NaN para valores v√°lidos
        media = 0.0 if np.isnan(media) else float(media)
        desvio_padrao = 0.0 if np.isnan(desvio_padrao) else float(desvio_padrao)
        variancia = 0.0 if np.isnan(variancia) else float(variancia)
        coeficiente_variacao = 0.0 if np.isnan(coeficiente_variacao) else float(coeficiente_variacao)
        
        # Identificar n√∫meros com maior e menor variabilidade
        numeros_mais_variaveis = sorted(frequencia_numeros.items(), key=lambda x: abs(x[1] - media), reverse=True)[:10]
        numeros_menos_variaveis = sorted(frequencia_numeros.items(), key=lambda x: abs(x[1] - media))[:10]
        
        return {
            'estatisticas_gerais': {
                'media_frequencia': float(media),
                'desvio_padrao': float(desvio_padrao),
                'variancia': float(variancia),
                'coeficiente_variacao': float(coeficiente_variacao),
                'total_concursos': int(len(self.df_validos))
            },
            'numeros_mais_variaveis': numeros_mais_variaveis,
            'numeros_menos_variaveis': numeros_menos_variaveis,
            'frequencia_completa': dict(frequencia_numeros)
        }
    
    def teste_aleatoriedade(self):
        """
        Realiza testes de aleatoriedade nos sorteios
        
        Returns:
            dict: Resultados dos testes de aleatoriedade
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Verificar se h√° dados suficientes
        if len(self.df_validos) < 2:
            return {
                'teste_chi_quadrado': {
                    'chi2': 0.0,
                    'p_value': 1.0,
                    'graus_liberdade': 0,
                    'aleatorio': True,
                    'interpretacao': 'Dados Insuficientes'
                },
                'teste_sequencias': {
                    'media_runs': 0.0,
                    'desvio_runs': 0.0,
                    'total_concursos': 0
                },
                'teste_paridade': {
                    'media_pares': 0.0,
                    'desvio_pares': 0.0,
                    'esperado': 3.0,
                    'aleatorio_paridade': True
                }
            }
        
        resultados = {}
        
        # 1. Teste Chi-quadrado para uniformidade
        todos_numeros = []
        for _, row in self.df_validos.iterrows():
            numeros_concurso = [row[col] for col in self.colunas_bolas if pd.notna(row[col])]
            todos_numeros.extend(numeros_concurso)
        
        frequencia_observada = Counter(todos_numeros)
        
        # Frequ√™ncia esperada (uniforme)
        total_sorteios = len(todos_numeros)
        if total_sorteios == 0:
            return {
                'teste_chi_quadrado': {
                    'chi2': 0.0,
                    'p_value': 1.0,
                    'graus_liberdade': 0,
                    'aleatorio': True,
                    'interpretacao': 'Dados Insuficientes'
                },
                'teste_sequencias': {
                    'media_runs': 0.0,
                    'desvio_runs': 0.0,
                    'total_concursos': 0
                },
                'teste_paridade': {
                    'media_pares': 0.0,
                    'desvio_pares': 0.0,
                    'esperado': 3.0,
                    'aleatorio_paridade': True
                }
            }
        frequencia_esperada = total_sorteios / 50  # 50 n√∫meros poss√≠veis
        
        # Preparar dados para chi-quadrado
        obs = [frequencia_observada.get(i, 0) for i in range(1, 51)]
        esp = [frequencia_esperada] * 50
        
        chi2, p_value, dof, expected = chi2_contingency([obs, esp])
        
        # Converter NaN para valores v√°lidos
        chi2 = 0.0 if np.isnan(chi2) else float(chi2)
        p_value = 1.0 if np.isnan(p_value) else float(p_value)
        dof = 0 if np.isnan(dof) else int(dof)
        
        resultados['teste_chi_quadrado'] = {
            'chi2': float(chi2),
            'p_value': float(p_value),
            'graus_liberdade': int(dof),
            'aleatorio': bool(p_value > 0.05),
            'interpretacao': 'Aleat√≥rio' if p_value > 0.05 else 'N√£o aleat√≥rio'
        }
        
        # 2. Teste de sequ√™ncias (Runs Test)
        # Verificar se h√° padr√µes de sequ√™ncia nos n√∫meros sorteados
        sequencias = []
        for _, row in self.df_validos.iterrows():
            numeros_concurso = sorted([row[col] for col in self.colunas_bolas if pd.notna(row[col])])
            # Contar sequ√™ncias consecutivas
            if len(numeros_concurso) > 1:
                runs = 1
                for i in range(1, len(numeros_concurso)):
                    if numeros_concurso[i] != numeros_concurso[i-1] + 1:
                        runs += 1
                sequencias.append(runs)
            else:
                sequencias.append(1)  # Se s√≥ h√° um n√∫mero, h√° 1 sequ√™ncia
        
        if sequencias:
            media_runs = np.mean(sequencias)
            desvio_runs = np.std(sequencias)
            
            # Converter NaN para valores v√°lidos
            media_runs = 0.0 if np.isnan(media_runs) else float(media_runs)
            desvio_runs = 0.0 if np.isnan(desvio_runs) else float(desvio_runs)
        else:
            media_runs = 0.0
            desvio_runs = 0.0
        
        resultados['teste_sequencias'] = {
            'media_runs': float(media_runs),
            'desvio_runs': float(desvio_runs),
            'total_concursos': int(len(sequencias))
        }
        
        # 3. Teste de paridade (distribui√ß√£o par/√≠mpar)
        pares_por_concurso = []
        for _, row in self.df_validos.iterrows():
            numeros_concurso = [row[col] for col in self.colunas_bolas if pd.notna(row[col])]
            pares = sum(1 for num in numeros_concurso if num % 2 == 0)
            pares_por_concurso.append(pares)
        
        media_pares = np.mean(pares_por_concurso)
        desvio_pares = np.std(pares_por_concurso)
        
        # Converter NaN para valores v√°lidos
        media_pares = 0.0 if np.isnan(media_pares) else float(media_pares)
        desvio_pares = 0.0 if np.isnan(desvio_pares) else float(desvio_pares)
        
        resultados['teste_paridade'] = {
            'media_pares': float(media_pares),
            'desvio_pares': float(desvio_pares),
            'esperado': 3.0,  # Esperado: 3 pares em 6 n√∫meros
            'aleatorio_paridade': bool(abs(media_pares - 3.0) < 0.5)
        }
        
        return resultados
    
    def analise_clusters(self, n_clusters=5):
        """
        Realiza an√°lise de clusters dos n√∫meros com m√©tricas avan√ßadas
        
        Args:
            n_clusters (int): N√∫mero de clusters a formar
            
        Returns:
            dict: Resultados da an√°lise de clusters com interpreta√ß√£o detalhada
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Criar matriz de caracter√≠sticas para cada n√∫mero
        caracteristicas = []
        numeros_analisados = []
        
        for numero in range(1, 51):
            # Caracter√≠sticas b√°sicas do n√∫mero
            freq_total = 0
            freq_recente = 0
            ultima_aparicao = 0
            media_aparicoes_concurso = 0
            
            # Novas m√©tricas avan√ßadas
            intervalos_aparicoes = []
            ultima_posicao = -1
            
            # Usar enumerate para ter controle sobre o √≠ndice
            for pos, (idx, row) in enumerate(self.df_validos.iterrows()):
                numeros_concurso = [row[col] for col in self.colunas_bolas if pd.notna(row[col])]
                if numero in numeros_concurso:
                    freq_total += 1
                    if pos < len(self.df_validos) * 0.3:  # √öltimos 30%
                        freq_recente += 1
                    ultima_aparicao = len(self.df_validos) - pos
                    
                    # Calcular intervalos entre apari√ß√µes
                    if ultima_posicao != -1:
                        intervalo = pos - ultima_posicao
                        intervalos_aparicoes.append(intervalo)
                    ultima_posicao = pos
            
            # Calcular m√©tricas avan√ßadas
            media_aparicoes_concurso = freq_total / len(self.df_validos) if len(self.df_validos) > 0 else 0
            intervalo_medio = np.mean(intervalos_aparicoes) if intervalos_aparicoes else len(self.df_validos)
            desvio_intervalo = np.std(intervalos_aparicoes) if len(intervalos_aparicoes) > 1 else 0
            score_atraso = ultima_aparicao / intervalo_medio if intervalo_medio > 0 else 0
            volatilidade = desvio_intervalo / intervalo_medio if intervalo_medio > 0 else 0
            
            # Tend√™ncia (comparar frequ√™ncia recente vs total)
            tendencia = (freq_recente / max(len(self.df_validos) * 0.3, 1)) - media_aparicoes_concurso
            
            caracteristicas.append([
                freq_total,           # 0: Frequ√™ncia total
                freq_recente,         # 1: Frequ√™ncia recente
                ultima_aparicao,      # 2: √öltima apari√ß√£o
                media_aparicoes_concurso,  # 3: M√©dia de apari√ß√µes
                intervalo_medio,      # 4: Intervalo m√©dio (NOVA)
                desvio_intervalo,     # 5: Desvio do intervalo (NOVA)
                score_atraso,         # 6: Score de atraso (NOVA)
                volatilidade,         # 7: Volatilidade (NOVA)
                tendencia,            # 8: Tend√™ncia (NOVA)
                numero                # 9: N√∫mero
            ])
            numeros_analisados.append(numero)
        
        # Verificar se h√° dados suficientes para clustering
        if len(self.df_validos) < n_clusters:
            # Se n√£o h√° dados suficientes, retornar clusters simples
            return {
                'clusters': {'cluster_0': list(range(1, 51))},
                'estatisticas_clusters': {
                    'cluster_0': {
                        'numeros': list(range(1, 51)),
                        'quantidade': 50,
                        'frequencia_media': 0.0,
                        'frequencia_recente_media': 0.0,
                        'ultima_aparicao_media': 0.0,
                        'tipo': 'Dados Insuficientes'
                    }
                },
                'centroids': [],
                'inertia': 0.0
            }
        
        # Normalizar caracter√≠sticas
        scaler = StandardScaler()
        caracteristicas_norm = scaler.fit_transform(caracteristicas)
        
        # Aplicar K-means
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(caracteristicas_norm)
        
        # Organizar resultados
        resultados_clusters = defaultdict(list)
        for i, cluster_id in enumerate(clusters):
            resultados_clusters[f'cluster_{cluster_id}'].append(numeros_analisados[i])
        
        # Calcular estat√≠sticas detalhadas de cada cluster
        estatisticas_clusters = {}
        resumo_clusters = {}
        
        for cluster_id in range(n_clusters):
            numeros_cluster = resultados_clusters[f'cluster_{cluster_id}']
            if numeros_cluster:
                # Calcular caracter√≠sticas m√©dias do cluster
                caracteristicas_cluster = [caracteristicas[i] for i, c in enumerate(clusters) if c == cluster_id]
                if caracteristicas_cluster:
                    # M√©tricas b√°sicas
                    media_freq = np.mean([c[0] for c in caracteristicas_cluster])
                    media_recente = np.mean([c[1] for c in caracteristicas_cluster])
                    media_ultima = np.mean([c[2] for c in caracteristicas_cluster])
                    media_intervalo = np.mean([c[4] for c in caracteristicas_cluster])
                    media_desvio = np.mean([c[5] for c in caracteristicas_cluster])
                    media_score_atraso = np.mean([c[6] for c in caracteristicas_cluster])
                    media_volatilidade = np.mean([c[7] for c in caracteristicas_cluster])
                    media_tendencia = np.mean([c[8] for c in caracteristicas_cluster])
                    
                    # Converter NaN para valores v√°lidos
                    media_freq = 0.0 if np.isnan(media_freq) else float(media_freq)
                    media_recente = 0.0 if np.isnan(media_recente) else float(media_recente)
                    media_ultima = 0.0 if np.isnan(media_ultima) else float(media_ultima)
                    media_intervalo = 0.0 if np.isnan(media_intervalo) else float(media_intervalo)
                    media_desvio = 0.0 if np.isnan(media_desvio) else float(media_desvio)
                    media_score_atraso = 0.0 if np.isnan(media_score_atraso) else float(media_score_atraso)
                    media_volatilidade = 0.0 if np.isnan(media_volatilidade) else float(media_volatilidade)
                    media_tendencia = 0.0 if np.isnan(media_tendencia) else float(media_tendencia)
                else:
                    media_freq = media_recente = media_ultima = media_intervalo = 0.0
                    media_desvio = media_score_atraso = media_volatilidade = media_tendencia = 0.0
                
                # Classificar cluster com m√©tricas avan√ßadas
                tipo_cluster = self._classificar_cluster_avancado(
                    media_freq, media_recente, media_ultima, 
                    media_intervalo, media_score_atraso, media_volatilidade, media_tendencia
                )
                
                # Gerar descri√ß√£o detalhada
                descricao_curta = self._gerar_descricao_cluster(
                    media_freq, media_recente, media_ultima, 
                    media_intervalo, media_score_atraso, media_volatilidade, media_tendencia,
                    len(numeros_cluster)
                )
                
                # Gerar recomenda√ß√£o de aposta
                recomendacao = self._gerar_recomendacao_cluster(tipo_cluster, media_score_atraso, media_volatilidade)
                
                # Estat√≠sticas b√°sicas (mantidas para compatibilidade)
                estatisticas_clusters[f'cluster_{cluster_id}'] = {
                    'numeros': numeros_cluster,
                    'quantidade': int(len(numeros_cluster)),
                    'frequencia_media': float(media_freq),
                    'frequencia_recente_media': float(media_recente),
                    'ultima_aparicao_media': float(media_ultima),
                    'tipo': tipo_cluster
                }
                
                # Resumo detalhado (nova estrutura)
                resumo_clusters[f'cluster_{cluster_id}'] = {
                    'id': f'Cluster {cluster_id}',
                    'descricao_curta': descricao_curta,
                    'caracteristicas_principais': {
                        'frequencia_media': round(media_freq, 2),
                        'intervalo_medio': round(media_intervalo, 2),
                        'score_atraso': round(media_score_atraso, 2),
                        'volatilidade': round(media_volatilidade, 2),
                        'tendencia': round(media_tendencia, 2)
                    },
                    'numeros_exemplos': sorted(numeros_cluster)[:min(len(numeros_cluster), 8)],
                    'todos_numeros_do_cluster': sorted(numeros_cluster),  # Lista COMPLETA ordenada
                    'tamanho': len(numeros_cluster),
                    'tipo': tipo_cluster,
                    'recomendacao': recomendacao,
                    'cor': self._obter_cor_cluster(tipo_cluster)
                }
        
        return {
            'clusters': dict(resultados_clusters),
            'estatisticas_clusters': estatisticas_clusters,
            'resumo_clusters': resumo_clusters,  # Nova estrutura detalhada
            'centroids': kmeans.cluster_centers_.tolist(),
            'inertia': float(kmeans.inertia_)
        }
    
    def _classificar_cluster_avancado(self, freq_media, freq_recente, ultima_aparicao, 
                                    intervalo_medio, score_atraso, volatilidade, tendencia):
        """Classifica o tipo de cluster baseado em m√©tricas avan√ßadas"""
        
        # Determinar perfil principal
        if freq_media > 8 and score_atraso < 0.5:
            if volatilidade > 0.5:
                return "Quente Vol√°til"
            else:
                return "Quente Est√°vel"
        elif freq_media <= 5 and score_atraso > 1.5:
            if volatilidade > 0.7:
                return "Frio Vol√°til"
            else:
                return "Frio Atrasado"
        elif score_atraso > 2.0:
            return "Muito Atrasado"
        elif volatilidade > 0.8:
            return "Altamente Vol√°til"
        elif tendencia > 0.1:
            return "Em Ascens√£o"
        elif tendencia < -0.1:
            return "Em Decl√≠nio"
        else:
            return "Equilibrado"
    
    def _classificar_cluster(self, freq_media, freq_recente, ultima_aparicao):
        """Classifica o tipo de cluster baseado nas caracter√≠sticas (mantido para compatibilidade)"""
        if freq_media > 8 and freq_recente > 2:
            return "Quente e Recente"
        elif freq_media > 8 and freq_recente <= 2:
            return "Quente mas Frio Recentemente"
        elif freq_media <= 5 and ultima_aparicao > 10:
            return "Frio e em Seca"
        elif freq_media <= 5 and ultima_aparicao <= 5:
            return "Frio mas Recente"
        else:
            return "Neutro"
    
    def _gerar_descricao_cluster(self, freq_media, freq_recente, ultima_aparicao, 
                                intervalo_medio, score_atraso, volatilidade, tendencia, tamanho):
        """Gera descri√ß√£o detalhada do cluster"""
        
        descricao = f"Este cluster (com {tamanho} n√∫meros) √© caracterizado por:"
        
        # Frequ√™ncia
        if freq_media > 8:
            descricao += f" alta frequ√™ncia m√©dia de {freq_media:.1f};"
        elif freq_media <= 5:
            descricao += f" baixa frequ√™ncia m√©dia de {freq_media:.1f};"
        else:
            descricao += f" frequ√™ncia m√©dia equilibrada de {freq_media:.1f};"
        
        # Intervalo
        descricao += f" intervalo m√©dio de {intervalo_medio:.1f} concursos;"
        
        # Score de atraso
        if score_atraso > 1.5:
            descricao += f" n√∫meros atrasados (score {score_atraso:.1f});"
        elif score_atraso < 0.5:
            descricao += f" n√∫meros recentes (score {score_atraso:.1f});"
        
        # Volatilidade
        if volatilidade > 0.7:
            descricao += f" alta volatilidade ({volatilidade:.1f});"
        elif volatilidade < 0.3:
            descricao += f" baixa volatilidade ({volatilidade:.1f});"
        
        # Tend√™ncia
        if tendencia > 0.1:
            descricao += f" tend√™ncia de ascens√£o;"
        elif tendencia < -0.1:
            descricao += f" tend√™ncia de decl√≠nio;"
        else:
            descricao += f" tend√™ncia est√°vel;"
        
        return descricao.rstrip(';') + "."
    
    def _gerar_recomendacao_cluster(self, tipo_cluster, score_atraso, volatilidade):
        """Gera recomenda√ß√£o de aposta baseada no tipo do cluster"""
        
        recomendacoes = {
            "Quente Vol√°til": "‚ö†Ô∏è Use com modera√ß√£o - pode esfriar rapidamente",
            "Quente Est√°vel": "‚úÖ Bom para apostas - padr√£o confi√°vel",
            "Frio Vol√°til": "üéØ Considere - pode surpreender, mas √© arriscado",
            "Frio Atrasado": "üî• Quente - alta probabilidade de sair em breve",
            "Muito Atrasado": "üî• Muito quente - muito prov√°vel de sair",
            "Altamente Vol√°til": "‚ö†Ô∏è Muito arriscado - comportamento imprevis√≠vel",
            "Em Ascens√£o": "üìà Promissor - tend√™ncia positiva",
            "Em Decl√≠nio": "üìâ Evite - tend√™ncia negativa",
            "Equilibrado": "‚öñÔ∏è Seguro - padr√£o est√°vel e previs√≠vel"
        }
        
        return recomendacoes.get(tipo_cluster, "ü§î Padr√£o n√£o identificado")
    
    def _obter_cor_cluster(self, tipo_cluster):
        """Retorna cor associada ao tipo do cluster"""
        
        cores = {
            "Quente Vol√°til": "#FF6B6B",      # Vermelho
            "Quente Est√°vel": "#4ECDC4",      # Verde
            "Frio Vol√°til": "#FFA07A",        # Laranja
            "Frio Atrasado": "#FFD93D",       # Amarelo
            "Muito Atrasado": "#FF8C00",      # Laranja escuro
            "Altamente Vol√°til": "#DDA0DD",   # Roxo
            "Em Ascens√£o": "#98FB98",         # Verde claro
            "Em Decl√≠nio": "#F08080",         # Rosa
            "Equilibrado": "#87CEEB"          # Azul claro
        }
        
        return cores.get(tipo_cluster, "#808080")  # Cinza como padr√£o
    
    def analise_correlacao_numeros(self):
        """
        Analisa correla√ß√£o entre n√∫meros
        
        Returns:
            dict: Matriz de correla√ß√£o e n√∫meros mais correlacionados
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Criar matriz de presen√ßa (concurso x n√∫mero)
        matriz_presenca = np.zeros((len(self.df_validos), 50))
        
        for pos, (idx, row) in enumerate(self.df_validos.iterrows()):
            numeros_concurso = [row[col] for col in self.colunas_bolas if pd.notna(row[col])]
            for numero in numeros_concurso:
                if 1 <= numero <= 50:
                    matriz_presenca[pos, numero - 1] = 1
        
        # Verificar se h√° dados suficientes para correla√ß√£o
        if len(self.df_validos) < 2:
            return {
                'matriz_correlacao': [],
                'correlacoes_positivas': [],
                'correlacoes_negativas': [],
                'correlacao_media': 0.0
            }
        
        # Calcular matriz de correla√ß√£o
        try:
            matriz_correlacao = np.corrcoef(matriz_presenca.T)
            
            # Encontrar pares mais correlacionados
            pares_correlacionados = []
            for i in range(50):
                for j in range(i + 1, 50):
                    if i < matriz_correlacao.shape[0] and j < matriz_correlacao.shape[1]:
                        correlacao = matriz_correlacao[i, j]
                        if not np.isnan(correlacao):
                            pares_correlacionados.append((i + 1, j + 1, correlacao))
        except Exception as e:
            logger.warning(f"Erro ao calcular correla√ß√£o: {e}")
            return {
                'matriz_correlacao': [],
                'correlacoes_positivas': [],
                'correlacoes_negativas': [],
                'correlacao_media': 0.0
            }
        
        # Ordenar por correla√ß√£o
        pares_correlacionados.sort(key=lambda x: abs(x[2]), reverse=True)
        
        # Separar correla√ß√µes positivas e negativas
        correlacoes_positivas = [(int(p[0]), int(p[1]), float(p[2])) for p in pares_correlacionados if p[2] > 0.1][:10]
        correlacoes_negativas = [(int(p[0]), int(p[1]), float(p[2])) for p in pares_correlacionados if p[2] < -0.1][:10]
        
        # Calcular correla√ß√£o m√©dia de forma segura
        try:
            triu_indices = np.triu_indices(50, k=1)
            if triu_indices[0].size > 0 and triu_indices[0].max() < matriz_correlacao.shape[0] and triu_indices[1].max() < matriz_correlacao.shape[1]:
                correlacao_media = float(np.mean(np.abs(matriz_correlacao[triu_indices])))
            else:
                correlacao_media = 0.0
        except:
            correlacao_media = 0.0
        
        return {
            'matriz_correlacao': matriz_correlacao.tolist(),
            'correlacoes_positivas': correlacoes_positivas,
            'correlacoes_negativas': correlacoes_negativas,
            'correlacao_media': correlacao_media
        }
    
    def probabilidades_condicionais(self):
        """
        Calcula probabilidades condicionais entre n√∫meros
        
        Returns:
            dict: Probabilidades condicionais
        """
        if self.df_validos is None or self.df_validos.empty:
            return {}
        
        # Verificar se h√° dados suficientes
        if len(self.df_validos) < 2:
            return {
                'probabilidades_completas': {},
                'dependencias_fortes': [],
                'total_concursos': 0
            }
        
        # Contar ocorr√™ncias de cada n√∫mero
        contagem_numeros = Counter()
        contagem_pares = Counter()
        
        # Garantir que todos os n√∫meros de 1 a 50 tenham uma contagem (mesmo que 0)
        for numero in range(1, 51):
            contagem_numeros[numero] = 0
        
        for _, row in self.df_validos.iterrows():
            numeros_concurso = [row[col] for col in self.colunas_bolas if pd.notna(row[col])]
            
            # Contar n√∫meros individuais
            for numero in numeros_concurso:
                contagem_numeros[numero] += 1
            
            # Contar pares
            for i in range(len(numeros_concurso)):
                for j in range(i + 1, len(numeros_concurso)):
                    par = tuple(sorted([numeros_concurso[i], numeros_concurso[j]]))
                    contagem_pares[par] += 1
        
        total_concursos = len(self.df_validos)
        if total_concursos == 0:
            return {
                'probabilidades_completas': {},
                'dependencias_fortes': [],
                'total_concursos': 0
            }
        
        probabilidades = {}
        
        # Calcular probabilidades condicionais
        for numero1 in range(1, 51):
            prob_numero1 = contagem_numeros[numero1] / total_concursos
            condicionais = {}
            
            for numero2 in range(1, 51):
                if numero1 != numero2:
                    # Probabilidade conjunta
                    par = tuple(sorted([numero1, numero2]))
                    prob_conjunta = contagem_pares[par] / total_concursos if total_concursos > 0 else 0
                    
                    # Probabilidade condicional P(numero2 | numero1)
                    if contagem_numeros[numero1] > 0:
                        prob_condicional = prob_conjunta / prob_numero1
                    else:
                        prob_condicional = 0
                    
                    # Medida de depend√™ncia
                    if prob_numero1 > 0 and total_concursos > 0:
                        prob_numero2 = contagem_numeros[numero2] / total_concursos
                        dependencia = prob_condicional / prob_numero2 if prob_numero2 > 0 else 0
                    else:
                        dependencia = 0
                    
                    condicionais[numero2] = {
                        'probabilidade_condicional': float(prob_condicional),
                        'dependencia': float(dependencia),
                        'probabilidade_conjunta': float(prob_conjunta)
                    }
            
            probabilidades[numero1] = {
                'probabilidade_marginal': float(prob_numero1),
                'condicionais': condicionais
            }
        
        # Encontrar as depend√™ncias mais fortes
        dependencias = []
        for num1 in range(1, 51):
            for num2 in range(1, 51):
                if num1 != num2:
                    dep = probabilidades[num1]['condicionais'][num2]['dependencia']
                    if dep > 1.5:  # Depend√™ncia forte
                        dependencias.append((int(num1), int(num2), float(dep)))
        
        dependencias.sort(key=lambda x: x[2], reverse=True)
        
        return {
            'probabilidades_completas': probabilidades,
            'dependencias_fortes': dependencias[:20],
            'total_concursos': int(total_concursos)
        }

    def calcular_distribuicao_frequencia_numeros(self, df_filtrado):
        """
        Calcula a frequ√™ncia de cada n√∫mero principal (1-50) em um DataFrame filtrado.
        Retorna uma lista de dicion√°rios com {numero: frequencia}.
        
        Args:
            df_filtrado (pd.DataFrame): DataFrame filtrado pela janela temporal
            
        Returns:
            list: Lista de dicion√°rios com n√∫mero e frequ√™ncia
        """
        try:
            if df_filtrado is None or df_filtrado.empty:
                logger.warning("DataFrame filtrado vazio para c√°lculo de distribui√ß√£o")
                return []
            
            # Concatena todas as colunas de n√∫meros principais em uma √∫nica Series
            todos_numeros = df_filtrado[self.colunas_bolas].values.flatten()
            
            # Conta a frequ√™ncia de cada n√∫mero
            contagem_numeros = Counter(todos_numeros)
            
            # Garante que todos os n√∫meros de 1 a 50 estejam presentes, mesmo com frequ√™ncia 0
            distribuicao = []
            for num in range(1, 51):  # N√∫meros de 1 a 50
                distribuicao.append({
                    'numero': num, 
                    'frequencia': contagem_numeros.get(num, 0)
                })
            
            logger.info(f"Distribui√ß√£o calculada para {len(df_filtrado)} concursos")
            return distribuicao
            
        except Exception as e:
            logger.error(f"Erro ao calcular distribui√ß√£o de frequ√™ncia: {e}")
            return []
    
    def executar_analise_completa(self, qtd_concursos=None):
        """
        Executa todas as an√°lises estat√≠sticas avan√ßadas
        
        Args:
            qtd_concursos (int, optional): Quantidade de concursos para an√°lise temporal
            
        Returns:
            dict: Resultados completos de todas as an√°lises
        """
        logger.info(f"Iniciando an√°lise estat√≠stica avan√ßada completa... (qtd_concursos: {qtd_concursos})")
        
        # Filtrar dados por per√≠odo se especificado
        df_analise = self.df_validos
        if qtd_concursos and qtd_concursos > 0:
            df_analise = self.df_validos.tail(qtd_concursos)
            logger.info(f"Analisando √∫ltimos {qtd_concursos} concursos ({len(df_analise)} encontrados)")
        
        # Criar inst√¢ncia tempor√°ria com dados filtrados
        analise_temp = AnaliseEstatisticaAvancada(df_analise)
        
        # Ajustar n√∫mero de clusters baseado no tamanho dos dados
        n_clusters = min(5, max(2, len(df_analise) // 5))  # Entre 2 e 5 clusters
        
        resultados = {
            'desvio_padrao_distribuicao': analise_temp.calcular_desvio_padrao_distribuicao(),
            'teste_aleatoriedade': analise_temp.teste_aleatoriedade(),
            'analise_clusters': analise_temp.analise_clusters(n_clusters=n_clusters),
            'analise_correlacao_numeros': analise_temp.analise_correlacao_numeros(),
            'probabilidades_condicionais': analise_temp.probabilidades_condicionais(),
            'distribuicao_numeros': self.calcular_distribuicao_frequencia_numeros(df_analise)
        }
        
        # Limpar valores NaN antes de retornar
        resultados = limpar_nan_do_dict(resultados)
        
        logger.info("An√°lise estat√≠stica avan√ßada conclu√≠da!")
        return resultados

def exibir_analise_estatistica_avancada(resultados):
    """
    Exibe os resultados da an√°lise estat√≠stica avan√ßada de forma formatada
    
    Args:
        resultados (dict): Resultados da an√°lise
    """
    print("\n" + "="*80)
    print("üìä AN√ÅLISE ESTAT√çSTICA AVAN√áADA - +MILION√ÅRIA")
    print("="*80)
    
    # 1. Desvio Padr√£o
    if 'desvio_padrao' in resultados and resultados['desvio_padrao']:
        print("\nüìà DESVIO PADR√ÉO DA DISTRIBUI√á√ÉO:")
        print("-" * 40)
        stats = resultados['desvio_padrao']['estatisticas_gerais']
        print(f"   M√©dia de frequ√™ncia: {stats['media_frequencia']:.2f}")
        print(f"   Desvio padr√£o: {stats['desvio_padrao']:.2f}")
        print(f"   Vari√¢ncia: {stats['variancia']:.2f}")
        print(f"   Coeficiente de varia√ß√£o: {stats['coeficiente_variacao']:.2f}%")
        
        print("\n   üî• N√∫meros mais vari√°veis:")
        for num, freq in resultados['desvio_padrao']['numeros_mais_variaveis'][:5]:
            print(f"      N√∫mero {num}: {freq} vezes")
    
    # 2. Teste de Aleatoriedade
    if 'aleatoriedade' in resultados and resultados['aleatoriedade']:
        print("\nüé≤ TESTE DE ALEATORIEDADE:")
        print("-" * 40)
        
        chi2 = resultados['aleatoriedade']['teste_chi_quadrado']
        print(f"   Teste Chi-quadrado:")
        print(f"      Valor: {chi2['chi2']:.4f}")
        print(f"      P-valor: {chi2['p_value']:.4f}")
        print(f"      Resultado: {chi2['interpretacao']}")
        
        paridade = resultados['aleatoriedade']['teste_paridade']
        print(f"   Teste de Paridade:")
        print(f"      M√©dia de pares: {paridade['media_pares']:.2f} (esperado: 3.0)")
        print(f"      Aleat√≥rio: {'Sim' if paridade['aleatorio_paridade'] else 'N√£o'}")
    
    # 3. An√°lise de Clusters
    if 'clusters' in resultados and resultados['clusters']:
        print("\nüîó AN√ÅLISE DE CLUSTERS:")
        print("-" * 40)
        
        for cluster_id, info in resultados['clusters']['estatisticas_clusters'].items():
            print(f"   {cluster_id.upper()} ({info['tipo']}):")
            print(f"      N√∫meros: {info['numeros']}")
            print(f"      Quantidade: {info['quantidade']}")
            print(f"      Frequ√™ncia m√©dia: {info['frequencia_media']:.2f}")
    
    # 4. Correla√ß√£o
    if 'correlacao' in resultados and resultados['correlacao']:
        print("\nüìà CORRELA√á√ÉO ENTRE N√öMEROS:")
        print("-" * 40)
        
        print("   üîó Correla√ß√µes positivas (tendem a sair juntos):")
        for num1, num2, corr in resultados['correlacao']['correlacoes_positivas'][:5]:
            print(f"      {num1} ‚Üî {num2}: {corr:.3f}")
        
        print("   üîÑ Correla√ß√µes negativas (raramente saem juntos):")
        for num1, num2, corr in resultados['correlacao']['correlacoes_negativas'][:5]:
            print(f"      {num1} ‚Üî {num2}: {corr:.3f}")
    
    # 5. Probabilidades Condicionais
    if 'probabilidades_condicionais' in resultados and resultados['probabilidades_condicionais']:
        print("\nüéØ PROBABILIDADES CONDICIONAIS:")
        print("-" * 40)
        
        print("   üí™ Depend√™ncias mais fortes:")
        for num1, num2, dep in resultados['probabilidades_condicionais']['dependencias_fortes'][:10]:
            print(f"      {num1} ‚Üí {num2}: {dep:.2f}x mais prov√°vel")

# Exemplo de uso
if __name__ == "__main__":
    try:
        from MilionariaFuncaCarregaDadosExcel import carregar_dados_milionaria
        
        print("üìä AN√ÅLISE ESTAT√çSTICA AVAN√áADA - +MILION√ÅRIA")
        print("="*80)
        
        df_milionaria = carregar_dados_milionaria()
        
        if df_milionaria is not None and not df_milionaria.empty:
            # Criar inst√¢ncia da an√°lise
            analise = AnaliseEstatisticaAvancada(df_milionaria)
            
            # Executar an√°lise completa
            resultados = analise.executar_analise_completa()
            
            # Exibir resultados
            exibir_analise_estatistica_avancada(resultados)
            
        else:
            print("‚ùå N√£o foi poss√≠vel carregar os dados da Milion√°ria")
            
    except ImportError:
        print("‚ö†Ô∏è  M√≥dulo de carregamento n√£o encontrado. Usando dados de exemplo...")
        
        # Dados de exemplo para teste
        dados_exemplo = [
            [1, 1, 3, 7, 15, 23, 44, 2, 4],
            [2, 13, 16, 35, 41, 42, 47, 2, 6],
            [3, 1, 9, 17, 30, 31, 44, 1, 4],
            [4, 6, 23, 25, 33, 34, 47, 1, 2],
            [5, 6, 16, 21, 24, 26, 45, 2, 5]
        ]
        df_exemplo = pd.DataFrame(dados_exemplo, columns=['Concurso', 'Bola1', 'Bola2', 'Bola3', 'Bola4', 'Bola5', 'Bola6', 'Trevo1', 'Trevo2'])
        
        analise = AnaliseEstatisticaAvancada(df_exemplo)
        resultados = analise.executar_analise_completa()
        exibir_analise_estatistica_avancada(resultados) 